â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Edit rfdetr/models/attention.py[0m                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           - v': :math:`[Vdims..., Eq]`[0m                                       â”‚
â”‚  [0m                                                                            â”‚
â”‚      """[0m                                                                     â”‚
â”‚      # Using descriptive variable names instead of single capitals[0m           â”‚
â”‚ -    dim_q, dim_k, dim_v = q.size(-1), k.size(-1), v.size(-1)  # noqa: N806[0m  â”‚
â”‚ +    dim_q, dim_k, dim_v = q.size(-1), k.size(-1), v.size(-1)[0m                â”‚
â”‚      assert w_q.shape == ([0m                                                   â”‚
â”‚          dim_q,[0m                                                              â”‚
â”‚          dim_q,[0m                                                              â”‚
â”‚      ), f"expecting query weights shape of {(dim_q, dim_q)}, but got {w_q...[0m â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Edit rfdetr/models/attention.py[0m                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              # self-attention[0m                                                â”‚
â”‚              return F.linear(q, w, b).chunk(3, dim=-1)[0m                       â”‚
â”‚          else:[0m                                                               â”‚
â”‚              # encoder-decoder attention[0m                                     â”‚
â”‚ -            w_q, w_kv = w.split([E, E * 2])[0m                                 â”‚
â”‚ +            w_q, w_kv = w.split([embedding_dim, embedding_dim * 2])[0m         â”‚
â”‚              if b is None:[0m                                                   â”‚
â”‚                  b_q = b_kv = None[0m                                           â”‚
â”‚              else:[0m                                                           â”‚
â”‚ -                b_q, b_kv = b.split([E, E * 2])[0m                             â”‚
â”‚ +                b_q, b_kv = b.split([embedding_dim, embedding_dim * 2])[0m     â”‚
â”‚              return (F.linear(q, w_q, b_q), *F.linear(k, w_kv, b_kv).chun...[0m â”‚
â”‚      else:[0m                                                                   â”‚
â”‚          w_q, w_k, w_v = w.chunk(3)[0m                                          â”‚
â”‚          if b is None:[0m                                                       â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

